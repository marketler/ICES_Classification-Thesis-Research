{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is used to perform all necessary data engineering steps to create the Single-Point dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy.distance\n",
    "from datetime import timedelta, datetime\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20756\\3001274411.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  world_ports_lim['coordinates'] = coords_test\n"
     ]
    }
   ],
   "source": [
    "# Import worldports dataset\n",
    "world_ports = pd.read_csv(\"Data\\\\wld_trs_ports_wfp.csv\", header=0)\n",
    "world_ports_lim = world_ports[['portname', 'latitude', 'longitude']]\n",
    "\n",
    "coords_test = tuple(zip(world_ports_lim['latitude'], world_ports_lim['longitude']))\n",
    "\n",
    "world_ports_lim['coordinates'] = coords_test\n",
    "\n",
    "array_world_ports_lim = np.array(world_ports_lim['coordinates'].tolist())\n",
    "\n",
    "#  Define function to find closest port by calculating the distance between all entries in data1 and data2\n",
    "def broadcasting_based_lng_lat(data1, data2):\n",
    "    # data1, data2 are the data arrays with 2 cols and they hold\n",
    "    # lat., lng. values in those cols respectively\n",
    "    data1 = np.deg2rad(data1)                     \n",
    "    data2 = np.deg2rad(data2)                     \n",
    "\n",
    "    lat1 = data1[:,0]                     \n",
    "    lng1 = data1[:,1]         \n",
    "\n",
    "    lat2 = data2[:,0]                     \n",
    "    lng2 = data2[:,1]         \n",
    "\n",
    "    diff_lat = lat1[:,None] - lat2\n",
    "    diff_lng = lng1[:,None] - lng2\n",
    "    d = np.sin(diff_lat/2)**2 + np.cos(lat1[:,None])*np.cos(lat2) * np.sin(diff_lng/2)**2\n",
    "    return 2 * 6371 * np.arcsin(np.sqrt(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_24632\\4126420135.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  acoustic_1_1['LogTime'] = pd.to_datetime(acoustic_1_1['LogTime'])\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_24632\\4126420135.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  biotic_1_1['HaulStartTime'] = pd.to_datetime(biotic_1_1['HaulStartTime'])\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_24632\\4126420135.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full['fishing'][track] = 1\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_24632\\4126420135.py:270: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  full_set['int_datetime'] =  full_set['datetimestamp'].astype('int64')\n"
     ]
    }
   ],
   "source": [
    "# Perform the data engineering\n",
    "k = 0\n",
    "list_of_df = []\n",
    "list_of_acoustic = []\n",
    "list_of_biotic = []\n",
    "\n",
    "survey_list = ['Data\\\\HERAS', 'Data\\\\IBWSS', 'Data\\\\IESSNS']\n",
    "\n",
    "# Loop over every file present in folder \"Data\\*survey*\\Biotic\"\n",
    "for survey in survey_list:\n",
    "       for filename in os.listdir(survey + \"\\\\Biotic\"):\n",
    "              k += 1\n",
    "              \n",
    "              # Read the biotic and accompanying acoustic files\n",
    "              acoustic_1 = pd.read_csv(survey + \"\\\\Acoustic\\\\Acoustic\" + filename[6:99], header=0)\n",
    "              biotic_1 = pd.read_csv(survey + \"\\\\Biotic\\\\\" + filename, header=0)\n",
    "\n",
    "              acoustic_1['Survey'] = survey[5:15]\n",
    "              acoustic_1['fileIDN'] = k\n",
    "\n",
    "              biotic_1['Survey'] = survey[5:15]\n",
    "              biotic_1['fileIDN'] = k\n",
    "\n",
    "              list_of_acoustic.append(acoustic_1)\n",
    "              list_of_biotic.append(biotic_1)\n",
    "              \n",
    "              # Remove invalid acoustic logs\n",
    "              acoustic_1 = acoustic_1.loc[acoustic_1['LogValidity'] == 'V']\n",
    "              \n",
    "              # Filter out the required columns\n",
    "              a_columns = ['LogTime', 'LogLatitude', 'LogLongitude']\n",
    "              b_columns = ['HaulStartTime', 'HaulDuration', 'HaulValidity', 'HaulStartLatitude', 'HaulStartLongitude', 'HaulStopLatitude', 'HaulStopLongitude', 'HaulDistance', 'HaulTowDirection']\n",
    "              acoustic_1_1 = acoustic_1[a_columns]\n",
    "              biotic_1_1 = biotic_1[b_columns]\n",
    "\n",
    "              # Set the datetime columns to correct datatype and drop duplicates\n",
    "              acoustic_1_1['LogTime'] = pd.to_datetime(acoustic_1_1['LogTime'])\n",
    "              biotic_1_1['HaulStartTime'] = pd.to_datetime(biotic_1_1['HaulStartTime'])\n",
    "              acoustic_1_1 = acoustic_1_1.drop_duplicates()\n",
    "              biotic_1_1 = biotic_1_1.drop_duplicates(subset=['HaulStartTime'])\n",
    "\n",
    "              # Prepare the biotic file to have the same structure as the acoustic file\n",
    "              bio_to_aco = biotic_1_1[['HaulStartTime', 'HaulStartLatitude', 'HaulStartLongitude']]\n",
    "              bio_to_aco = bio_to_aco.rename(columns={'HaulStartTime': 'LogTime', 'HaulStartLatitude': 'LogLatitude', 'HaulStartLongitude': 'LogLongitude'})\n",
    "\n",
    "              # Concat the biotic and acoustic file to create a df containing all registered timestamps\n",
    "              acoustic_final = pd.concat([acoustic_1_1, bio_to_aco], ignore_index=True)\n",
    "              acoustic_final = acoustic_final.sort_values('LogTime', ignore_index=True)\n",
    "              acoustic_final['fileIDN'] = k\n",
    "\n",
    "              # Index both final sets over their respective timestamp columns\n",
    "              acoustic_final2 = acoustic_final.set_index('LogTime')\n",
    "              biotic_final = biotic_1_1.set_index('HaulStartTime')\n",
    "\n",
    "              # Perform final concat adding all available columns to the available timestamps and create new column containing binary classifier for fishing or not.\n",
    "              full = pd.concat([acoustic_final2, biotic_final], axis=1)\n",
    "              full['fishing'] = 0\n",
    "              full.loc[full['HaulValidity'] == 'V', 'fishing'] = 1\n",
    "              full = full.drop('HaulValidity', axis=1)\n",
    "       \n",
    "              \n",
    "              # Extend the fishing period (fishing = 1) over all rows that are within the start-end haul timeframe\n",
    "              # -----------------------------------------------------------------------------------------------------------------------------\n",
    "              time_str = '1/1/1900 12:00:00.0000'\n",
    "              date_format_str = '%d/%m/%Y %H:%M:%S.%f'\n",
    "\n",
    "              track = 1\n",
    "              start_haul = datetime.strptime(time_str, date_format_str)\n",
    "              end_haul = datetime.strptime(time_str, date_format_str)\n",
    "              index = full.index\n",
    "              while track < full.shape[0]:\n",
    "                     if full['HaulDuration'][track] > 0:\n",
    "                            start_haul = index[track]\n",
    "                            end_haul = index[track] + timedelta(minutes=full['HaulDuration'][track])\n",
    "              \n",
    "                     if index[track] >= start_haul and index[track] <= end_haul:\n",
    "                            full['fishing'][track] = 1\n",
    "                     track += 1\n",
    "              # -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "              # Calculate speed\n",
    "              # -----------------------------------------------------------------------------------------------------------------------------\n",
    "              full = full[['LogLatitude', 'LogLongitude', 'fishing', 'fileIDN']]\n",
    "              distances = [0]\n",
    "              durations = [0]\n",
    "              index = full.index\n",
    "              i=0\n",
    "              while i < full.shape[0] - 1:\n",
    "                     distances.append(geopy.distance.distance((full['LogLatitude'][i], full['LogLongitude'][i]), (full['LogLatitude'][i+1], full['LogLongitude'][i+1])).km)\n",
    "                     durations.append((index[i+1] - index[i]).total_seconds())\n",
    "                     i += 1\n",
    "\n",
    "              km_s = [0]\n",
    "              j=1\n",
    "              while j < len(distances):\n",
    "                     if durations[j] != 0:\n",
    "                            km_s.append((distances[j]/durations[j]) * 60 * 60)\n",
    "                     else:\n",
    "                            km_s.append(0)\n",
    "                     j += 1\n",
    "\n",
    "              full['speed'] = km_s\n",
    "              # -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "              # Calculate speeds based on lag/lead\n",
    "              # -----------------------------------------------------------------------------------------------------------------------------\n",
    "              speed_lag_1 = []\n",
    "              speed_lead_1 = []\n",
    "              speed_both_1 = []\n",
    "              speed_lag_2 = []\n",
    "              speed_lead_2 = []\n",
    "              speed_both_2 = []\n",
    "\n",
    "              full['lag_1'] = full['speed'].shift(1)\n",
    "              full['lag_2'] = full['speed'].shift(2)\n",
    "              full['lead_1'] = full['speed'].shift(-1)\n",
    "              full['lead_2'] = full['speed'].shift(-2)\n",
    "\n",
    "              m = 0\n",
    "              while m < full.shape[0]:\n",
    "                     speed_current = full['speed'][m]\n",
    "                     lag_1 = full['lag_1'][m]\n",
    "                     lag_2 = full['lag_2'][m]\n",
    "                     lead_1 = full['lead_1'][m]\n",
    "                     lead_2 = full['lead_2'][m]\n",
    "\n",
    "                     if math.isnan(lag_1):\n",
    "                            average_speed_lg1 = speed_current\n",
    "                     else:\n",
    "                            average_speed_lg1 = (speed_current + lag_1) / 2\n",
    "                     \n",
    "                     if math.isnan(lag_2) and math.isnan(lag_1):\n",
    "                            average_speed_lg2 = speed_current\n",
    "                     elif math.isnan(lag_2) and not math.isnan(lag_1):\n",
    "                            average_speed_lg2 = (speed_current + lag_1) / 2\n",
    "                     else:\n",
    "                            average_speed_lg2 = (speed_current + lag_1 + lag_2) / 3\n",
    "                     \n",
    "                     if math.isnan(lead_1):\n",
    "                            average_speed_ld1 = speed_current\n",
    "                     else:\n",
    "                            average_speed_ld1 = (speed_current + lead_1) / 2\n",
    "                     \n",
    "                     if math.isnan(lead_2) and math.isnan(lead_1):\n",
    "                            average_speed_ld2 = speed_current\n",
    "                     elif math.isnan(lead_2) and not math.isnan(lead_1):\n",
    "                            average_speed_ld2 = (speed_current + lead_1) / 2\n",
    "                     else:\n",
    "                            average_speed_ld2 = (speed_current + lead_1 + lead_2) / 3\n",
    "                     \n",
    "                     if math.isnan(lead_1):\n",
    "                            average_speed_b1 = (speed_current + lag_1) / 2\n",
    "                     elif math.isnan(lag_1):\n",
    "                            average_speed_b1 = (speed_current + lead_1) / 2\n",
    "                     else:\n",
    "                            average_speed_b1 = (speed_current + lead_1 + lag_1) / 3\n",
    "                     \n",
    "                     if math.isnan(lead_1):\n",
    "                            average_speed_b2 = (speed_current + lag_1 + lag_2) / 3\n",
    "                     elif math.isnan(lead_2):\n",
    "                            average_speed_b2 = (speed_current + lag_1 + lag_2 + lead_1) / 4\n",
    "                     elif math.isnan(lag_1):\n",
    "                            average_speed_b2 = (speed_current + lead_1 + lead_2) / 3\n",
    "                     elif math.isnan(lag_2):\n",
    "                            average_speed_b2 = (speed_current + lead_1 + lead_2 + lag_1) / 4\n",
    "                     else:\n",
    "                            average_speed_b2 = (speed_current + lead_1 + lag_1 + lead_2 + lag_2) / 5\n",
    "\n",
    "                     speed_lag_1.append(average_speed_lg1)\n",
    "                     speed_lag_2.append(average_speed_lg2)\n",
    "                     speed_lead_1.append(average_speed_ld1)\n",
    "                     speed_lead_2.append(average_speed_ld2)\n",
    "                     speed_both_1.append(average_speed_b1)\n",
    "                     speed_both_2.append(average_speed_b2)\n",
    "                     \n",
    "                     m += 1\n",
    "\n",
    "              full['speed_lag_1'] = speed_lag_1\n",
    "              full['speed_lag_2'] = speed_lag_2\n",
    "              full['speed_lead_1'] = speed_lead_1\n",
    "              full['speed_lead_2'] = speed_lead_2\n",
    "              full['speed_both_1'] = speed_both_1\n",
    "              full['speed_both_2'] = speed_both_2\n",
    "              # -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "              # Calculate direction based on previous and next\n",
    "              # -----------------------------------------------------------------------------------------------------------------------------\n",
    "              # Create lag and lead of lat/long\n",
    "              full['lat_f1'] = full['LogLatitude'].shift(-1) # latitude with lead 1\n",
    "              full['lon_f1'] = full['LogLongitude'].shift(-1) # Longtitude with lead 1\n",
    "              full['lat_b1'] = full['LogLatitude'].shift(1) # latitude with lag 1\n",
    "              full['lon_b1'] = full['LogLongitude'].shift(1) # Longtitude with lag 1\n",
    "\n",
    "              direction = [0]\n",
    "              geo_track = 1\n",
    "              while geo_track < full.shape[0]:\n",
    "                     delta_lon = full['LogLongitude'][geo_track] - full['lon_b1'][geo_track]\n",
    "                     y2 = math.sin(delta_lon) * math.cos(full['LogLatitude'][geo_track])\n",
    "                     x2 = math.cos(full['lat_b1'][geo_track]) * math.sin(full['LogLatitude'][geo_track]) - math.sin(full['lat_b1'][geo_track]) * math.cos(full['LogLatitude'][geo_track]) * math.cos(delta_lon)\n",
    "\n",
    "                     brng2 = math.atan2(y2, x2)\n",
    "                     brng2 = math.degrees(brng2)\n",
    "\n",
    "                     direction.append(brng2)\n",
    "\n",
    "                     geo_track += 1\n",
    "\n",
    "              full['bearing'] = direction\n",
    "\n",
    "              direction_change = [0, 0]\n",
    "              geo_track2 = 2\n",
    "              while geo_track2 < full.shape[0]:\n",
    "                     change = full['bearing'][geo_track2 - 1] - full['bearing'][geo_track2]\n",
    "                     direction_change.append(change)\n",
    "\n",
    "                     geo_track2 += 1\n",
    "\n",
    "              full['bearing change'] = direction_change\n",
    "              # -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "              # Calculate distance to port\n",
    "              # -----------------------------------------------------------------------------------------------------------------------------\n",
    "              cur_loc = 0\n",
    "              port_distances = []\n",
    "\n",
    "              while cur_loc < full.shape[0]:\n",
    "                     cord = np.array([(full['LogLatitude'][cur_loc], full['LogLongitude'][cur_loc])])\n",
    "                     p_dist = broadcasting_based_lng_lat(cord, array_world_ports_lim)\n",
    "                     port_distances.append(p_dist.min())\n",
    "\n",
    "                     cur_loc += 1\n",
    "\n",
    "              full['distance to port'] = port_distances\n",
    "              # -----------------------------------------------------------------------------------------------------------------------------\n",
    "              \n",
    "              \n",
    "              # add time deltas\n",
    "              # -----------------------------------------------------------------------------------------------------------------------------\n",
    "              moment = 1\n",
    "              time_deltas = [0]\n",
    "              index = full.index\n",
    "              while moment < full.shape[0]:\n",
    "                     time_delta = (index[moment] - index[moment - 1]).total_seconds()\n",
    "                     time_deltas.append(time_delta)\n",
    "                     moment += 1\n",
    "\n",
    "              full['time delta'] = time_deltas   \n",
    "              # -----------------------------------------------------------------------------------------------------------------------------\n",
    "              \n",
    "              full['survey'] = survey[5:15]\n",
    "              list_of_df.append(full) # Add calculated df to list of lists to be transformed back to a final df at the end\n",
    "\n",
    "all_acoustic = pd.concat(list_of_acoustic, ignore_index=False)\n",
    "all_biotic = pd.concat(list_of_biotic, ignore_index=False)\n",
    "\n",
    "all_acoustic.to_csv('Data/all_acoustic.csv')\n",
    "all_biotic.to_csv('Data/all_biotic.csv')\n",
    "\n",
    "full_set = pd.concat(list_of_df,ignore_index=False) # transform list of lists to final df\n",
    "full_set.reset_index(inplace=True)\n",
    "\n",
    "# rename columns\n",
    "full_set = full_set.rename(columns={\"index\": \"datetimestamp\"})\n",
    "\n",
    "# convert datetime to int\n",
    "full_set['int_datetime'] =  full_set['datetimestamp'].astype('int64')\n",
    "\n",
    "full_set.to_csv('Data/full_set_SPA.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
